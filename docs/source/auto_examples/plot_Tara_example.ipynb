{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Ocean salinity prediction based on marin microbiome data\n\nWe repoduce an example of prediction of ocean salinity over ocean microbiome data\nthat has been introduced in `this article <https://www.biorxiv.org/content/10.1101/2020.09.01.277632v1.full>`_,\nwhere the R package `trac <https://github.com/jacobbien/trac>`_ (which uses c-lasso)\nhas been used. \n\n\n\nBien, J., Yan, X., Simpson, L. and M\u00fcller, C. (2020).\nTree-Aggregated Predictive Modeling of Microbiome Data :\n\n\"Integrative marine data collection efforts such as Tara Oceans (Sunagawa et al., 2020)\nor the Simons CMAP (https://simonscmap.com)\nprovide the means to investigate ocean ecosystems on a global scale.\nUsing Tara\u2019s environmental and microbial survey of ocean surface water (Sunagawa, 2015),\nwe next illustrate how trac can be used to globally connect environmental covariates\nand the ocean microbiome. As an example, we learn a global predictive model of ocean salinity\nfrom n = 136 samples and p = 8916 miTAG OTUs (Logares et al., 2014).\ntrac identifies four taxonomic aggregations,\nthe kingdom bacteria and the phylum Bacteroidetes being negatively associated\nand the classes Alpha and Gammaproteobacteria being positively associated with marine salinity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from classo import classo_problem\nimport matplotlib.pyplot as plt\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# import rpy in order to read data generated on R\nimport rpy2.robjects as ro\nfrom rpy2.robjects.packages import importr\n\n# this code code be used in order to import R library Matrix\nutils = importr('utils')    \nutils.chooseCRANmirror(ind=1) #\nutils.install_packages('Matrix')\nimportr('Matrix')\n\n#Open R file tara_sal_processed.RDS\nfile = 'Tara/tara_sal_processed.RDS'\nrds = ro.r['readRDS'](file)\n\nrA = ro.r[\"as.matrix\"](rds[4])\nx = np.array(rds[1])\ny = np.array(rds[0])\nA = np.array(rA)\n\nlabel_OTU = rds[1].colnames\nlabel_sample =rds[1].rownames\nlabel_nodes = np.array(list(rA.colnames))\nlabel_short = np.array([l.split(\"::\")[-1] for l in label_nodes])\nprint(y.shape)\nprint(x.shape)\nprint(A.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process similar to 2fit_trac_model.R\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# first need to load \"tara_sal_trac.Rdata\"\n# in order to extract training set we are using\nro.r['load'](\"Tara/tara_sal_trac.RData\")\n\n\ncvfit = ro.r[\"cvfit\"]\ncv = cvfit.rx(\"cv\")\nlambda_1SE = cv.rx(\"lambda_1se\")\n\ntr = np.array(ro.r['tr']) - 1  # python index starts at 0 when R index starts at 1\nte = np.array([i for i in range(len(y)) if not i in tr])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process similar to trac\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pseudo_count = 1\nX = np.log(pseudo_count+x)\nnleaves = np.sum(A,axis = 0)\nlogGeom = X.dot(A)/nleaves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross validation and Path Computation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problem = classo_problem(logGeom[tr], y[tr], label = label_short)\n\nproblem.formulation.w = 1/nleaves\nproblem.formulation.intercept     = True\nproblem.formulation.concomitant = False\n\nproblem.model_selection.StabSel   = False\nproblem.model_selection.PATH   = True\nproblem.model_selection.CV   = True\nproblem.model_selection.CVparameters.seed = 6 # one could change logscale, Nsubset, oneSE\nprint(problem)\n\nproblem.solve()\nprint(problem.solution)\n\n\nselection = problem.solution.CV.selected_param[1:] # exclude the intercept\nprint(label_nodes[selection])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alpha = problem.solution.CV.refit\nyhat = logGeom[te].dot(alpha[1:])+alpha[0]\n\nM1, M2 = max(y[te]), min(y[te])\nplt.plot(yhat, y[te], 'bo', label = 'sample of the testing set')\nplt.plot([M1, M2], [M1, M2], 'k-', label = \"identity\")\nplt.xlabel('predictor yhat'), plt.ylabel('real y'), plt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stability selection\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problem = classo_problem(logGeom[tr], y[tr], label = label_short)\n\nproblem.formulation.w = 1/nleaves\nproblem.formulation.intercept     = True\nproblem.formulation.concomitant = False\n\n\nproblem.model_selection.PATH   = False\nproblem.model_selection.CV   = False\n# can change q, B, nS, method, threshold etc in problem.model_selection.StabSelparameters\n\nproblem.solve()\n\nprint(problem, problem.solution)\n\nselection = problem.solution.StabSel.selected_param[1:] # exclude the intercept\nprint(label_nodes[selection])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alpha = problem.solution.StabSel.refit\nyhat = logGeom[te].dot(alpha[1:])+alpha[0]\n\nM1, M2 = max(y[te]), min(y[te])\nplt.plot(yhat, y[te], 'bo', label = 'sample of the testing set')\nplt.plot([M1, M2],[M1, M2], 'k-', label = \"identity\")\nplt.xlabel('predictor yhat'), plt.ylabel('real y'), plt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}